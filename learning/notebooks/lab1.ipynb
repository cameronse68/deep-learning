{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37164bitdlvirtualenvacda6f43192945da980010b4722f7019",
   "display_name": "Python 3.7.1 64-bit ('dl': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "/Users/sarahcameron/Documents/personal_git/deep-learning\n"
    }
   ],
   "source": [
    "import os \n",
    "from pathlib import Path \n",
    "try: \n",
    "    # '.' if the path is to current folder \n",
    "    os.chdir(Path(os.path.join(os.getcwd(), \".\")).parents[1]) \n",
    "    print(os.getcwd()) \n",
    "except: \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import mitdeeplearning as mdl\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import functools\n",
    "from IPython import display as ipythondisplay\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(logging.NullHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning.utils.convert import vectorize_string, get_batch\n",
    "from learning.model import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 816 songs in text\n"
    }
   ],
   "source": [
    "songs = mdl.lab1.load_training_data()\n",
    "songs_joined=\"\\n\\n\".join(songs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_songs,idx2char=vectorize_string(songs_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Step   0\n  input: 15 ('3')\n  expected output: 82 ('|')\nStep   1\n  input: 82 ('|')\n  expected output: 59 ('d')\nStep   2\n  input: 59 ('d')\n  expected output: 55 ('_')\nStep   3\n  input: 55 ('_')\n  expected output: 60 ('e')\nStep   4\n  input: 60 ('e')\n  expected output: 59 ('d')\n"
    }
   ],
   "source": [
    "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
    "\n",
    "for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
    "    print(\"Step {:3d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(len(idx2char), embedding_dim=256, rnn_units=1024, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (32, None, 256)           21248     \n_________________________________________________________________\nlstm (LSTM)                  (32, None, 1024)          5246976   \n=================================================================\nTotal params: 5,268,224\nTrainable params: 5,268,224\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Input shape:       (32, 100)  # (batch_size, sequence_length)\nPrediction shape:  (32, 100, 1024) # (batch_size, sequence_length, vocab_size)\n"
    }
   ],
   "source": [
    "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n",
    "pred = model(x)\n",
    "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
    "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  }
 ]
}