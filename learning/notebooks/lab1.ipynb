{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37164bitdlvirtualenvacda6f43192945da980010b4722f7019",
   "display_name": "Python 3.7.1 64-bit ('dl': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "/Users/sarahcameron/Documents/personal_git/deep-learning\n"
    }
   ],
   "source": [
    "import os \n",
    "from pathlib import Path \n",
    "try: \n",
    "    # '.' if the path is to current folder \n",
    "    os.chdir(Path(os.path.join(os.getcwd(), \".\")).parents[1]) \n",
    "    print(os.getcwd()) \n",
    "except: \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import mitdeeplearning as mdl\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import functools\n",
    "from IPython import display as ipythondisplay\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(logging.NullHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning.utils.convert import vectorize_string, get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 816 songs in text\n"
    }
   ],
   "source": [
    "songs = mdl.lab1.load_training_data()\n",
    "songs_joined=\"\\n\\n\".join(songs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_songs,idx2char=vectorize_string(songs_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Step   0\n  input: 29 ('D')\n  expected output: 22 (':')\nStep   1\n  input: 22 (':')\n  expected output: 82 ('|')\nStep   2\n  input: 82 ('|')\n  expected output: 2 ('!')\nStep   3\n  input: 2 ('!')\n  expected output: 0 ('\\n')\nStep   4\n  input: 0 ('\\n')\n  expected output: 0 ('\\n')\n"
    }
   ],
   "source": [
    "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
    "\n",
    "for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
    "    print(\"Step {:3d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch.shape"
   ]
  }
 ]
}